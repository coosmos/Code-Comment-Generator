{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tnBO8YFSgcGn",
        "outputId": "a372e948-b899-4fc5-ec66-6b2f3c22680a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Code Snippets: 823\n",
            "Total Comments: 823\n",
            "\n",
            "Sample Extracted Code Snippets: [\"def write_file(filename, content=None): with open(filename, 'w') as f: f.write(content)\", \"def count_vowels(s): return sum(1 for c in s if c.lower() in 'aeiou')\"]\n",
            "\n",
            "Sample Extracted Comments: ['Write content to a file', 'Count vowels in a string']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m170,752\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m95,232\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │        \u001b[38;5;34m394,240\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │        \u001b[38;5;34m394,240\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot (\u001b[38;5;33mDot\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m90\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                           │                        │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m90\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot_1 (\u001b[38;5;33mDot\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dot_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│                           │                        │                │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m744\u001b[0m)        │        \u001b[38;5;34m381,672\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">170,752</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">95,232</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                           │                        │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│                           │                        │                │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">744</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">381,672</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,436,136\u001b[0m (5.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,436,136</span> (5.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,436,136\u001b[0m (5.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,436,136</span> (5.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.4023 - loss: 4.9388 - val_accuracy: 0.5394 - val_loss: 2.7050\n",
            "Epoch 2/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5319 - loss: 2.6060 - val_accuracy: 0.5768 - val_loss: 2.5308\n",
            "Epoch 3/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5841 - loss: 2.4012 - val_accuracy: 0.5960 - val_loss: 2.4002\n",
            "Epoch 4/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5962 - loss: 2.2690 - val_accuracy: 0.6212 - val_loss: 2.3409\n",
            "Epoch 5/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6047 - loss: 2.2192 - val_accuracy: 0.6222 - val_loss: 2.2912\n",
            "Epoch 6/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6227 - loss: 2.1232 - val_accuracy: 0.6424 - val_loss: 2.2245\n",
            "Epoch 7/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6337 - loss: 2.0434 - val_accuracy: 0.6566 - val_loss: 2.1489\n",
            "Epoch 8/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6539 - loss: 1.9242 - val_accuracy: 0.6677 - val_loss: 2.0708\n",
            "Epoch 9/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6653 - loss: 1.8022 - val_accuracy: 0.6717 - val_loss: 2.0062\n",
            "Epoch 10/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6733 - loss: 1.7173 - val_accuracy: 0.6737 - val_loss: 1.9281\n",
            "Epoch 11/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6784 - loss: 1.6426 - val_accuracy: 0.6828 - val_loss: 1.8726\n",
            "Epoch 12/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6850 - loss: 1.5350 - val_accuracy: 0.6869 - val_loss: 1.8253\n",
            "Epoch 13/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6938 - loss: 1.4865 - val_accuracy: 0.6919 - val_loss: 1.7970\n",
            "Epoch 14/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7009 - loss: 1.4003 - val_accuracy: 0.6980 - val_loss: 1.7670\n",
            "Epoch 15/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7071 - loss: 1.3851 - val_accuracy: 0.7020 - val_loss: 1.7416\n",
            "Epoch 16/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7179 - loss: 1.2817 - val_accuracy: 0.7111 - val_loss: 1.7015\n",
            "Epoch 17/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7182 - loss: 1.2676 - val_accuracy: 0.7121 - val_loss: 1.6763\n",
            "Epoch 18/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7330 - loss: 1.1863 - val_accuracy: 0.7222 - val_loss: 1.6588\n",
            "Epoch 19/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7457 - loss: 1.1255 - val_accuracy: 0.7212 - val_loss: 1.6307\n",
            "Epoch 20/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7486 - loss: 1.0971 - val_accuracy: 0.7293 - val_loss: 1.6178\n",
            "Epoch 21/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7626 - loss: 1.0318 - val_accuracy: 0.7293 - val_loss: 1.5998\n",
            "Epoch 22/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7654 - loss: 1.0038 - val_accuracy: 0.7323 - val_loss: 1.5776\n",
            "Epoch 23/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7734 - loss: 0.9693 - val_accuracy: 0.7333 - val_loss: 1.5702\n",
            "Epoch 24/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7850 - loss: 0.9063 - val_accuracy: 0.7394 - val_loss: 1.5501\n",
            "Epoch 25/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7972 - loss: 0.8495 - val_accuracy: 0.7424 - val_loss: 1.5362\n",
            "Epoch 26/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8053 - loss: 0.8245 - val_accuracy: 0.7424 - val_loss: 1.5160\n",
            "Epoch 27/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8090 - loss: 0.8170 - val_accuracy: 0.7475 - val_loss: 1.5054\n",
            "Epoch 28/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8220 - loss: 0.7669 - val_accuracy: 0.7535 - val_loss: 1.5000\n",
            "Epoch 29/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8296 - loss: 0.7240 - val_accuracy: 0.7586 - val_loss: 1.5141\n",
            "Epoch 30/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8402 - loss: 0.6917 - val_accuracy: 0.7586 - val_loss: 1.5063\n",
            "Epoch 31/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8516 - loss: 0.6754 - val_accuracy: 0.7616 - val_loss: 1.4868\n",
            "Epoch 32/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8488 - loss: 0.6491 - val_accuracy: 0.7576 - val_loss: 1.5152\n",
            "Epoch 33/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8544 - loss: 0.6310 - val_accuracy: 0.7657 - val_loss: 1.4895\n",
            "Epoch 34/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8684 - loss: 0.5706 - val_accuracy: 0.7717 - val_loss: 1.4762\n",
            "Epoch 35/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8678 - loss: 0.5708 - val_accuracy: 0.7687 - val_loss: 1.4681\n",
            "Epoch 36/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8707 - loss: 0.5446 - val_accuracy: 0.7677 - val_loss: 1.4689\n",
            "Epoch 37/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8783 - loss: 0.5315 - val_accuracy: 0.7798 - val_loss: 1.4445\n",
            "Epoch 38/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8887 - loss: 0.4942 - val_accuracy: 0.7818 - val_loss: 1.4700\n",
            "Epoch 39/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8914 - loss: 0.4738 - val_accuracy: 0.7879 - val_loss: 1.4617\n",
            "Epoch 40/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8907 - loss: 0.4686 - val_accuracy: 0.7919 - val_loss: 1.4663\n",
            "Epoch 41/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9001 - loss: 0.4330 - val_accuracy: 0.7919 - val_loss: 1.4705\n",
            "Epoch 42/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9039 - loss: 0.4212 - val_accuracy: 0.7929 - val_loss: 1.4599\n",
            "Epoch 43/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9061 - loss: 0.4088 - val_accuracy: 0.7970 - val_loss: 1.4560\n",
            "Epoch 44/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9110 - loss: 0.3880 - val_accuracy: 0.7899 - val_loss: 1.4616\n",
            "Epoch 45/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9089 - loss: 0.3857 - val_accuracy: 0.7919 - val_loss: 1.4582\n",
            "Epoch 46/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9057 - loss: 0.3908 - val_accuracy: 0.7980 - val_loss: 1.4593\n",
            "Epoch 47/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9128 - loss: 0.3705 - val_accuracy: 0.7990 - val_loss: 1.4472\n",
            "Epoch 48/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9113 - loss: 0.3643 - val_accuracy: 0.8000 - val_loss: 1.4526\n",
            "Epoch 49/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9142 - loss: 0.3565 - val_accuracy: 0.8020 - val_loss: 1.4570\n",
            "Epoch 50/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9162 - loss: 0.3412 - val_accuracy: 0.8020 - val_loss: 1.4557\n",
            "Epoch 51/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9203 - loss: 0.3393 - val_accuracy: 0.8030 - val_loss: 1.4150\n",
            "Epoch 52/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9210 - loss: 0.3310 - val_accuracy: 0.8101 - val_loss: 1.4267\n",
            "Epoch 53/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9237 - loss: 0.3220 - val_accuracy: 0.8091 - val_loss: 1.4258\n",
            "Epoch 54/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9276 - loss: 0.3036 - val_accuracy: 0.8111 - val_loss: 1.4251\n",
            "Epoch 55/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9302 - loss: 0.2922 - val_accuracy: 0.8071 - val_loss: 1.4262\n",
            "Epoch 56/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9294 - loss: 0.2898 - val_accuracy: 0.8101 - val_loss: 1.4350\n",
            "Epoch 57/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9316 - loss: 0.2761 - val_accuracy: 0.8081 - val_loss: 1.4323\n",
            "Epoch 58/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9352 - loss: 0.2690 - val_accuracy: 0.8131 - val_loss: 1.4427\n",
            "Epoch 59/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9372 - loss: 0.2524 - val_accuracy: 0.8111 - val_loss: 1.4380\n",
            "Epoch 60/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9378 - loss: 0.2521 - val_accuracy: 0.8141 - val_loss: 1.4352\n",
            "Epoch 61/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9404 - loss: 0.2415 - val_accuracy: 0.8091 - val_loss: 1.4541\n",
            "Epoch 62/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9411 - loss: 0.2408 - val_accuracy: 0.8131 - val_loss: 1.4569\n",
            "Epoch 63/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9392 - loss: 0.2407 - val_accuracy: 0.8111 - val_loss: 1.4671\n",
            "Epoch 64/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9326 - loss: 0.2683 - val_accuracy: 0.8121 - val_loss: 1.4573\n",
            "Epoch 65/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9334 - loss: 0.2604 - val_accuracy: 0.8141 - val_loss: 1.4438\n",
            "Epoch 66/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9411 - loss: 0.2367 - val_accuracy: 0.8182 - val_loss: 1.4531\n",
            "Epoch 67/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9441 - loss: 0.2275 - val_accuracy: 0.8192 - val_loss: 1.4391\n",
            "Epoch 68/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9460 - loss: 0.2160 - val_accuracy: 0.8152 - val_loss: 1.4791\n",
            "Epoch 69/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9422 - loss: 0.2314 - val_accuracy: 0.8202 - val_loss: 1.4660\n",
            "Epoch 70/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9481 - loss: 0.2161 - val_accuracy: 0.8212 - val_loss: 1.4718\n",
            "Epoch 71/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9487 - loss: 0.2119 - val_accuracy: 0.8182 - val_loss: 1.4663\n",
            "Epoch 72/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9477 - loss: 0.2087 - val_accuracy: 0.8202 - val_loss: 1.4707\n",
            "Epoch 73/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9507 - loss: 0.2087 - val_accuracy: 0.8202 - val_loss: 1.4728\n",
            "Epoch 74/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9456 - loss: 0.2086 - val_accuracy: 0.8242 - val_loss: 1.4623\n",
            "Epoch 75/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9521 - loss: 0.1929 - val_accuracy: 0.8222 - val_loss: 1.4662\n",
            "Epoch 76/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9526 - loss: 0.1884 - val_accuracy: 0.8222 - val_loss: 1.4690\n",
            "Epoch 77/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9550 - loss: 0.1826 - val_accuracy: 0.8222 - val_loss: 1.4761\n",
            "Epoch 78/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9545 - loss: 0.1799 - val_accuracy: 0.8202 - val_loss: 1.4701\n",
            "Epoch 79/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9549 - loss: 0.1728 - val_accuracy: 0.8192 - val_loss: 1.4868\n",
            "Epoch 80/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9561 - loss: 0.1732 - val_accuracy: 0.8253 - val_loss: 1.4925\n",
            "Epoch 81/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9570 - loss: 0.1719 - val_accuracy: 0.8232 - val_loss: 1.4896\n",
            "Epoch 82/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9597 - loss: 0.1646 - val_accuracy: 0.8253 - val_loss: 1.4774\n",
            "Epoch 83/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9601 - loss: 0.1600 - val_accuracy: 0.8263 - val_loss: 1.4774\n",
            "Epoch 84/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9596 - loss: 0.1633 - val_accuracy: 0.8232 - val_loss: 1.4779\n",
            "Epoch 85/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9610 - loss: 0.1569 - val_accuracy: 0.8283 - val_loss: 1.4939\n",
            "Epoch 86/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9630 - loss: 0.1504 - val_accuracy: 0.8253 - val_loss: 1.4782\n",
            "Epoch 87/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9638 - loss: 0.1492 - val_accuracy: 0.8303 - val_loss: 1.4919\n",
            "Epoch 88/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9673 - loss: 0.1369 - val_accuracy: 0.8313 - val_loss: 1.4850\n",
            "Epoch 89/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9633 - loss: 0.1434 - val_accuracy: 0.8313 - val_loss: 1.4977\n",
            "Epoch 90/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9645 - loss: 0.1387 - val_accuracy: 0.8273 - val_loss: 1.4986\n",
            "Epoch 91/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.1347 - val_accuracy: 0.8333 - val_loss: 1.5060\n",
            "Epoch 92/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9703 - loss: 0.1265 - val_accuracy: 0.8303 - val_loss: 1.5148\n",
            "Epoch 93/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9701 - loss: 0.1248 - val_accuracy: 0.8354 - val_loss: 1.5033\n",
            "Epoch 94/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9681 - loss: 0.1277 - val_accuracy: 0.8323 - val_loss: 1.5092\n",
            "Epoch 95/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9663 - loss: 0.1242 - val_accuracy: 0.8323 - val_loss: 1.5221\n",
            "Epoch 96/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9705 - loss: 0.1189 - val_accuracy: 0.8333 - val_loss: 1.5173\n",
            "Epoch 97/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.1187 - val_accuracy: 0.8333 - val_loss: 1.5185\n",
            "Epoch 98/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9693 - loss: 0.1199 - val_accuracy: 0.8343 - val_loss: 1.5175\n",
            "Epoch 99/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9716 - loss: 0.1187 - val_accuracy: 0.8323 - val_loss: 1.5093\n",
            "Epoch 100/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9687 - loss: 0.1266 - val_accuracy: 0.8212 - val_loss: 1.4898\n",
            "Epoch 101/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9697 - loss: 0.1255 - val_accuracy: 0.8242 - val_loss: 1.4911\n",
            "Epoch 102/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9663 - loss: 0.1319 - val_accuracy: 0.8303 - val_loss: 1.5006\n",
            "Epoch 103/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9672 - loss: 0.1364 - val_accuracy: 0.8202 - val_loss: 1.4484\n",
            "Epoch 104/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9706 - loss: 0.1252 - val_accuracy: 0.8242 - val_loss: 1.4731\n",
            "Epoch 105/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9750 - loss: 0.1136 - val_accuracy: 0.8313 - val_loss: 1.4820\n",
            "Epoch 106/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9693 - loss: 0.1168 - val_accuracy: 0.8303 - val_loss: 1.4726\n",
            "Epoch 107/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9773 - loss: 0.1043 - val_accuracy: 0.8364 - val_loss: 1.4907\n",
            "Epoch 108/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9739 - loss: 0.1078 - val_accuracy: 0.8303 - val_loss: 1.5077\n",
            "Epoch 109/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9701 - loss: 0.1160 - val_accuracy: 0.8242 - val_loss: 1.5164\n",
            "Epoch 110/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9719 - loss: 0.1098 - val_accuracy: 0.8333 - val_loss: 1.5000\n",
            "Epoch 111/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9743 - loss: 0.1066 - val_accuracy: 0.8273 - val_loss: 1.5151\n",
            "Epoch 112/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9771 - loss: 0.0969 - val_accuracy: 0.8333 - val_loss: 1.5059\n",
            "Epoch 113/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9775 - loss: 0.0959 - val_accuracy: 0.8313 - val_loss: 1.5157\n",
            "Epoch 114/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9771 - loss: 0.0913 - val_accuracy: 0.8343 - val_loss: 1.5028\n",
            "Epoch 115/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9775 - loss: 0.0888 - val_accuracy: 0.8374 - val_loss: 1.5075\n",
            "Epoch 116/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9818 - loss: 0.0836 - val_accuracy: 0.8364 - val_loss: 1.5042\n",
            "Epoch 117/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9807 - loss: 0.0813 - val_accuracy: 0.8343 - val_loss: 1.5210\n",
            "Epoch 118/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9826 - loss: 0.0776 - val_accuracy: 0.8394 - val_loss: 1.5167\n",
            "Epoch 119/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9823 - loss: 0.0720 - val_accuracy: 0.8384 - val_loss: 1.5284\n",
            "Epoch 120/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9816 - loss: 0.0730 - val_accuracy: 0.8354 - val_loss: 1.5347\n",
            "Epoch 121/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9837 - loss: 0.0706 - val_accuracy: 0.8374 - val_loss: 1.5347\n",
            "Epoch 122/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9842 - loss: 0.0680 - val_accuracy: 0.8374 - val_loss: 1.5384\n",
            "Epoch 123/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9840 - loss: 0.0648 - val_accuracy: 0.8374 - val_loss: 1.5344\n",
            "Epoch 124/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9841 - loss: 0.0677 - val_accuracy: 0.8384 - val_loss: 1.5429\n",
            "Epoch 125/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9843 - loss: 0.0650 - val_accuracy: 0.8354 - val_loss: 1.5460\n",
            "Epoch 126/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9852 - loss: 0.0617 - val_accuracy: 0.8364 - val_loss: 1.5422\n",
            "Epoch 127/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9850 - loss: 0.0587 - val_accuracy: 0.8374 - val_loss: 1.5499\n",
            "Epoch 128/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9867 - loss: 0.0531 - val_accuracy: 0.8384 - val_loss: 1.5541\n",
            "Epoch 129/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9861 - loss: 0.0551 - val_accuracy: 0.8364 - val_loss: 1.5634\n",
            "Epoch 130/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9876 - loss: 0.0554 - val_accuracy: 0.8354 - val_loss: 1.5622\n",
            "Epoch 131/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9877 - loss: 0.0523 - val_accuracy: 0.8374 - val_loss: 1.5648\n",
            "Epoch 132/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9888 - loss: 0.0545 - val_accuracy: 0.8414 - val_loss: 1.5605\n",
            "Epoch 133/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9849 - loss: 0.0609 - val_accuracy: 0.8424 - val_loss: 1.5523\n",
            "Epoch 134/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.0523 - val_accuracy: 0.8384 - val_loss: 1.5659\n",
            "Epoch 135/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9874 - loss: 0.0535 - val_accuracy: 0.8424 - val_loss: 1.5587\n",
            "Epoch 136/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9879 - loss: 0.0508 - val_accuracy: 0.8414 - val_loss: 1.5388\n",
            "Epoch 137/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9884 - loss: 0.0521 - val_accuracy: 0.8384 - val_loss: 1.5495\n",
            "Epoch 138/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9860 - loss: 0.0543 - val_accuracy: 0.8364 - val_loss: 1.5313\n",
            "Epoch 139/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9835 - loss: 0.0612 - val_accuracy: 0.8364 - val_loss: 1.5730\n",
            "Epoch 140/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9820 - loss: 0.0783 - val_accuracy: 0.8313 - val_loss: 1.5192\n",
            "Epoch 141/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9783 - loss: 0.0867 - val_accuracy: 0.8384 - val_loss: 1.4869\n",
            "Epoch 142/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9822 - loss: 0.0773 - val_accuracy: 0.8333 - val_loss: 1.4906\n",
            "Epoch 143/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9840 - loss: 0.0700 - val_accuracy: 0.8404 - val_loss: 1.5103\n",
            "Epoch 144/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9844 - loss: 0.0687 - val_accuracy: 0.8364 - val_loss: 1.5382\n",
            "Epoch 145/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9838 - loss: 0.0709 - val_accuracy: 0.8384 - val_loss: 1.5065\n",
            "Epoch 146/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9867 - loss: 0.0610 - val_accuracy: 0.8313 - val_loss: 1.5236\n",
            "Epoch 147/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9867 - loss: 0.0557 - val_accuracy: 0.8384 - val_loss: 1.5185\n",
            "Epoch 148/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9890 - loss: 0.0488 - val_accuracy: 0.8404 - val_loss: 1.5139\n",
            "Epoch 149/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9926 - loss: 0.0395 - val_accuracy: 0.8384 - val_loss: 1.5253\n",
            "Epoch 150/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9912 - loss: 0.0405 - val_accuracy: 0.8374 - val_loss: 1.5371\n",
            "Epoch 151/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9914 - loss: 0.0376 - val_accuracy: 0.8374 - val_loss: 1.5368\n",
            "Epoch 152/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9921 - loss: 0.0342 - val_accuracy: 0.8384 - val_loss: 1.5454\n",
            "Epoch 153/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9928 - loss: 0.0324 - val_accuracy: 0.8374 - val_loss: 1.5508\n",
            "Epoch 154/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9947 - loss: 0.0287 - val_accuracy: 0.8343 - val_loss: 1.5505\n",
            "Epoch 155/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9916 - loss: 0.0323 - val_accuracy: 0.8364 - val_loss: 1.5512\n",
            "Epoch 156/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9922 - loss: 0.0311 - val_accuracy: 0.8394 - val_loss: 1.5615\n",
            "Epoch 157/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9923 - loss: 0.0308 - val_accuracy: 0.8414 - val_loss: 1.5586\n",
            "Epoch 158/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9931 - loss: 0.0283 - val_accuracy: 0.8364 - val_loss: 1.5681\n",
            "Epoch 159/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9935 - loss: 0.0292 - val_accuracy: 0.8394 - val_loss: 1.5698\n",
            "Epoch 160/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9939 - loss: 0.0233 - val_accuracy: 0.8374 - val_loss: 1.5751\n",
            "Epoch 161/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9935 - loss: 0.0274 - val_accuracy: 0.8384 - val_loss: 1.5751\n",
            "Epoch 162/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9944 - loss: 0.0246 - val_accuracy: 0.8414 - val_loss: 1.5759\n",
            "Epoch 163/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9952 - loss: 0.0209 - val_accuracy: 0.8404 - val_loss: 1.5823\n",
            "Epoch 164/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9943 - loss: 0.0249 - val_accuracy: 0.8424 - val_loss: 1.5780\n",
            "Epoch 165/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9929 - loss: 0.0286 - val_accuracy: 0.8384 - val_loss: 1.5874\n",
            "Epoch 166/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9930 - loss: 0.0272 - val_accuracy: 0.8364 - val_loss: 1.5835\n",
            "Epoch 167/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9930 - loss: 0.0269 - val_accuracy: 0.8404 - val_loss: 1.5871\n",
            "Epoch 168/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9934 - loss: 0.0265 - val_accuracy: 0.8414 - val_loss: 1.5992\n",
            "Epoch 169/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9931 - loss: 0.0264 - val_accuracy: 0.8404 - val_loss: 1.5935\n",
            "Epoch 170/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9955 - loss: 0.0221 - val_accuracy: 0.8444 - val_loss: 1.5848\n",
            "Epoch 171/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9946 - loss: 0.0199 - val_accuracy: 0.8455 - val_loss: 1.5982\n",
            "Epoch 172/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9959 - loss: 0.0182 - val_accuracy: 0.8465 - val_loss: 1.5877\n",
            "Epoch 173/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9953 - loss: 0.0173 - val_accuracy: 0.8455 - val_loss: 1.5937\n",
            "Epoch 174/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9957 - loss: 0.0182 - val_accuracy: 0.8465 - val_loss: 1.5859\n",
            "Epoch 175/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9961 - loss: 0.0183 - val_accuracy: 0.8465 - val_loss: 1.5998\n",
            "Epoch 176/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9958 - loss: 0.0168 - val_accuracy: 0.8444 - val_loss: 1.5984\n",
            "Epoch 177/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 0.8444 - val_loss: 1.6078\n",
            "Epoch 178/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9958 - loss: 0.0186 - val_accuracy: 0.8444 - val_loss: 1.6069\n",
            "Epoch 179/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9952 - loss: 0.0184 - val_accuracy: 0.8455 - val_loss: 1.6030\n",
            "Epoch 180/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9954 - loss: 0.0175 - val_accuracy: 0.8475 - val_loss: 1.6048\n",
            "Epoch 181/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9957 - loss: 0.0155 - val_accuracy: 0.8444 - val_loss: 1.6080\n",
            "Epoch 182/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9964 - loss: 0.0149 - val_accuracy: 0.8465 - val_loss: 1.6049\n",
            "Epoch 183/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9951 - loss: 0.0158 - val_accuracy: 0.8455 - val_loss: 1.6011\n",
            "Epoch 184/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9955 - loss: 0.0140 - val_accuracy: 0.8485 - val_loss: 1.6141\n",
            "Epoch 185/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9959 - loss: 0.0137 - val_accuracy: 0.8455 - val_loss: 1.6111\n",
            "Epoch 186/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9960 - loss: 0.0151 - val_accuracy: 0.8444 - val_loss: 1.6131\n",
            "Epoch 187/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9962 - loss: 0.0139 - val_accuracy: 0.8465 - val_loss: 1.6161\n",
            "Epoch 188/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9961 - loss: 0.0136 - val_accuracy: 0.8444 - val_loss: 1.6204\n",
            "Epoch 189/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9962 - loss: 0.0117 - val_accuracy: 0.8475 - val_loss: 1.6201\n",
            "Epoch 190/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9968 - loss: 0.0130 - val_accuracy: 0.8444 - val_loss: 1.6177\n",
            "Epoch 191/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9959 - loss: 0.0118 - val_accuracy: 0.8475 - val_loss: 1.6056\n",
            "Epoch 192/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9955 - loss: 0.0133 - val_accuracy: 0.8465 - val_loss: 1.6147\n",
            "Epoch 193/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9971 - loss: 0.0118 - val_accuracy: 0.8475 - val_loss: 1.6168\n",
            "Epoch 194/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9973 - loss: 0.0126 - val_accuracy: 0.8465 - val_loss: 1.6256\n",
            "Epoch 195/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0117 - val_accuracy: 0.8495 - val_loss: 1.6264\n",
            "Epoch 196/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0130 - val_accuracy: 0.8465 - val_loss: 1.6367\n",
            "Epoch 197/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9957 - loss: 0.0156 - val_accuracy: 0.8515 - val_loss: 1.6536\n",
            "Epoch 198/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9904 - loss: 0.0347 - val_accuracy: 0.8323 - val_loss: 1.6649\n",
            "Epoch 199/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9756 - loss: 0.0919 - val_accuracy: 0.8263 - val_loss: 1.6673\n",
            "Epoch 200/200\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9806 - loss: 0.0797 - val_accuracy: 0.8333 - val_loss: 1.5965\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8397 - loss: 1.2929 \n",
            "Test Loss: 1.2408, Test Accuracy: 0.8485\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "Code: from collections import Counter; def count_characters(text): return Counter(text)\n",
            "\n",
            "Generated Comment: take a name as input and return a greeting\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def cube(n): return n ** 3\n",
            "\n",
            "Generated Comment: find the cube of a number\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def power(base, exp): return base ** exp\n",
            "\n",
            "Generated Comment: compute the power of a number\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def is_leap_year(year): return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n",
            "\n",
            "Generated Comment: check if a given year is a leap year\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def factorial_iterative(n):      result = 1     for i in range(2, n + 1): result *= i     return result\n",
            "\n",
            "Generated Comment: find the factorial of a number using iteration\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def lcm_list(lst):      import math     from functools import reduce     return reduce(lambda x, y: (x * y) // math.gcd(x, y), lst)\n",
            "\n",
            "Generated Comment: train a decision tree classifier\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def delete_kubernetes_pod(pod_name):     import os     os.system(f\"kubectl delete pod {pod_name}\")     return f\"Pod {pod_name} deleted\"\n",
            "\n",
            "Generated Comment: delete a kubernetes pod\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def set_cors_headers(response):     response.headers[\"Access-Control-Allow-Origin\"] = \"*\"     response.headers[\"Access-Control-Allow-Methods\"] = \"GET,POST,PUT,DELETE\"     return response\n",
            "\n",
            "Generated Comment: generate a new bitcoin address using iptables\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "def insert_into_table(db_name, table_name, data):     import sqlite3     conn = sqlite3.connect(f\"{db_name}.db\")     cursor = conn.cursor()     placeholders = \", \".join([\"?\" for _ in data])     cursor.execute(f\"INSERT INTO {table_name} VALUES ({placeholders})\", data)     conn.commit()     conn.close()     return \"Data inserted successfully\"\n",
            "\n",
            "Generated Comment: fetch all records from a table\n",
            "\n",
            "Enter your Python code snippet (or type 'exit' to quit):\n",
            "exit\n",
            "Exiting program. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dot, Activation, Concatenate\n",
        "import pickle  # For saving and loading tokenizers\n",
        "from sklearn.model_selection import train_test_split  # For dataset splitting\n",
        "\n",
        "# -------------------------\n",
        "# 🛠️ Part 1: Data Preprocessing & Splitting Dataset\n",
        "# -------------------------\n",
        "\n",
        "def read_txt(file_path):\n",
        "    \"\"\" Reads text from a .txt file \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return file.read()\n",
        "\n",
        "# Read dataset\n",
        "data = read_txt('dataset.txt')\n",
        "\n",
        "# Updated regex pattern to match the specific dataset format\n",
        "pattern = r'Code:\\s*(.*?)\\n#\\s*(.*?)(?=\\nCode:|$)'\n",
        "matches = re.findall(pattern, data, re.DOTALL)\n",
        "\n",
        "# Extract code snippets and comments from matches\n",
        "code_snippets = []\n",
        "comments = []\n",
        "\n",
        "for code, comment in matches:\n",
        "    code_snippets.append(code.strip())\n",
        "    comments.append(comment.strip())\n",
        "\n",
        "# Debugging: Print dataset stats\n",
        "print(\"Total Code Snippets:\", len(code_snippets))\n",
        "print(\"Total Comments:\", len(comments))\n",
        "print(\"\\nSample Extracted Code Snippets:\", code_snippets[:2])\n",
        "print(\"\\nSample Extracted Comments:\", comments[:2])\n",
        "\n",
        "# Ensure dataset has enough samples before splitting\n",
        "if len(code_snippets) == 0 or len(comments) == 0:\n",
        "    raise ValueError(\"Dataset extraction failed! Check dataset format and regex patterns.\")\n",
        "\n",
        "# Split dataset (80% Training, 20% Testing)\n",
        "train_x, test_x, train_y, test_y = train_test_split(\n",
        "    code_snippets, comments, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Add start/end tokens to comments for sequence generation\n",
        "train_y = ['start ' + comment + ' end' for comment in train_y]\n",
        "test_y = ['start ' + comment + ' end' for comment in test_y]\n",
        "\n",
        "# Tokenize code and comments\n",
        "code_tokenizer = Tokenizer()\n",
        "code_tokenizer.fit_on_texts(train_x)\n",
        "code_sequences_train = code_tokenizer.texts_to_sequences(train_x)\n",
        "code_sequences_test = code_tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "comment_tokenizer = Tokenizer()\n",
        "comment_tokenizer.fit_on_texts(train_y)\n",
        "comment_sequences_train = comment_tokenizer.texts_to_sequences(train_y)\n",
        "comment_sequences_test = comment_tokenizer.texts_to_sequences(test_y)\n",
        "\n",
        "# Padding sequences\n",
        "max_code_len = max(len(seq) for seq in code_sequences_train)\n",
        "max_comment_len = max(len(seq) for seq in comment_sequences_train)\n",
        "\n",
        "code_padded_train = pad_sequences(code_sequences_train, maxlen=max_code_len, padding='post')\n",
        "code_padded_test = pad_sequences(code_sequences_test, maxlen=max_code_len, padding='post')\n",
        "\n",
        "comment_padded_train = pad_sequences(comment_sequences_train, maxlen=max_comment_len, padding='post')\n",
        "comment_padded_test = pad_sequences(comment_sequences_test, maxlen=max_comment_len, padding='post')\n",
        "\n",
        "# Save tokenizers and sequence lengths for inference\n",
        "with open(\"code_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(code_tokenizer, f)\n",
        "with open(\"comment_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(comment_tokenizer, f)\n",
        "# Save max lengths\n",
        "with open(\"max_lengths.pkl\", \"wb\") as f:\n",
        "    pickle.dump((max_code_len, max_comment_len), f)\n",
        "\n",
        "# -------------------------\n",
        "# 🧠 Part 2: Build RNN Model with Attention\n",
        "# -------------------------\n",
        "\n",
        "# Define encoder (Code Input)\n",
        "code_input = Input(shape=(max_code_len,))\n",
        "code_embedding = Embedding(input_dim=len(code_tokenizer.word_index) + 1, output_dim=128)(code_input)\n",
        "\n",
        "# Encoder LSTM\n",
        "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "encoder_output, state_h, state_c = encoder_lstm(code_embedding)\n",
        "\n",
        "# Define decoder\n",
        "decoder_input = Input(shape=(max_comment_len,))\n",
        "decoder_embedding = Embedding(input_dim=len(comment_tokenizer.word_index) + 1, output_dim=128)(decoder_input)\n",
        "\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_output, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention Layer\n",
        "attention = Dot(axes=[2, 2])([decoder_output, encoder_output])\n",
        "attention = Activation('softmax')(attention)\n",
        "context = Dot(axes=[2, 1])([attention, encoder_output])\n",
        "\n",
        "# Combine context with decoder output\n",
        "decoder_combined = Concatenate(axis=-1)([context, decoder_output])\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(len(comment_tokenizer.word_index) + 1, activation='softmax')(decoder_combined)\n",
        "\n",
        "# Define model\n",
        "model = Model([code_input, decoder_input], output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# -------------------------\n",
        "# 🚀 Part 3: Train the Model & Evaluate on Test Data\n",
        "# -------------------------\n",
        "\n",
        "# Prepare targets for training (shifted by one position for teacher forcing)\n",
        "decoder_target_data = np.zeros_like(comment_padded_train)\n",
        "for i in range(len(comment_padded_train)):\n",
        "    decoder_target_data[i, :-1] = comment_padded_train[i, 1:]\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    [code_padded_train, comment_padded_train],\n",
        "    decoder_target_data,\n",
        "    epochs=200,  # Reduced epochs for faster training, increase for better results\n",
        "    batch_size=32,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"code_comment_attention.keras\")\n",
        "\n",
        "# Evaluate model on test data\n",
        "decoder_test_target_data = np.zeros_like(comment_padded_test)\n",
        "for i in range(len(comment_padded_test)):\n",
        "    decoder_test_target_data[i, :-1] = comment_padded_test[i, 1:]\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate([code_padded_test, comment_padded_test], decoder_test_target_data)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# 🔥 Part 4: Inference Function for Generating Comments\n",
        "# -------------------------\n",
        "\n",
        "def generate_comment(code_text):\n",
        "    \"\"\"Generate a comment for the given code using beam search\"\"\"\n",
        "    # Load saved artifacts\n",
        "    try:\n",
        "        with open(\"code_tokenizer.pkl\", \"rb\") as f:\n",
        "            code_tokenizer = pickle.load(f)\n",
        "        with open(\"comment_tokenizer.pkl\", \"rb\") as f:\n",
        "            comment_tokenizer = pickle.load(f)\n",
        "        with open(\"max_lengths.pkl\", \"rb\") as f:\n",
        "            max_code_len, max_comment_len = pickle.load(f)\n",
        "\n",
        "        model = load_model(\"code_comment_attention.keras\")\n",
        "\n",
        "        # Process input code\n",
        "        code_seq = code_tokenizer.texts_to_sequences([code_text])\n",
        "        code_padded = pad_sequences(code_seq, maxlen=max_code_len, padding='post')\n",
        "\n",
        "        # Initialize with start token\n",
        "        state_value = None\n",
        "        target_seq = np.zeros((1, max_comment_len))\n",
        "        target_seq[0, 0] = comment_tokenizer.word_index.get('start', 1)\n",
        "\n",
        "        # Output sequence\n",
        "        output_words = []\n",
        "\n",
        "        # Generate the output sequence word by word\n",
        "        for i in range(max_comment_len - 1):\n",
        "            output_tokens = model.predict([code_padded, target_seq], verbose=0)\n",
        "\n",
        "            # Sample token with highest probability\n",
        "            sampled_token_index = np.argmax(output_tokens[0, i, :])\n",
        "            sampled_word = comment_tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word\n",
        "            if sampled_word == 'end' or sampled_word == '':\n",
        "                break\n",
        "\n",
        "            if sampled_word != 'start':  # Don't add the start token to output\n",
        "                output_words.append(sampled_word)\n",
        "\n",
        "            # Update target sequence for next token prediction\n",
        "            target_seq[0, i+1] = sampled_token_index\n",
        "\n",
        "        return ' '.join(output_words)\n",
        "    except Exception as e:\n",
        "        return f\"Error generating comment: {str(e)}\"\n",
        "\n",
        "# -------------------------\n",
        "# 🎉 Part 5: Take User Input & Generate Comments\n",
        "# -------------------------\n",
        "\n",
        "while True:\n",
        "    user_code = input(\"\\nEnter your Python code snippet (or type 'exit' to quit):\\n\")\n",
        "    if user_code.lower() == \"exit\":\n",
        "        print(\"Exiting program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    generated_comment = generate_comment(user_code)\n",
        "    print(\"\\nGenerated Comment:\", generated_comment)"
      ]
    }
  ]
}